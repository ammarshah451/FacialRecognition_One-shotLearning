{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#look at README file(mandatory) and requirements.txt first if not using google co lab\n",
        "#(much preferred to download all of the requirements them just in case)"
      ],
      "metadata": {
        "id": "EwIKnvJ7Djlq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install insightface onnxruntime"
      ],
      "metadata": {
        "id": "NLsuOyALSAcC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from insightface.app import FaceAnalysis\n",
        "\n",
        "app = FaceAnalysis(name=\"buffalo_l\", providers=['CPUExecutionProvider'])\n",
        "app.prepare(ctx_id=0)"
      ],
      "metadata": {
        "id": "I1yiy_QHFRGN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "mC0tcMahzKNe"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# --------------------------- Configuration -----------------------------------\n",
        "db_path = 'db'\n",
        "group_photo_dir = 'group_photos'\n",
        "supported_exts = ('.jpg', '.jpeg', '.png')\n",
        "standard_display_width = 800\n",
        "\n",
        "# ---------------------- Augmentation Transforms ----------------------\n",
        "augmentation_transforms = [\n",
        "    transforms.RandomRotation(degrees=20),\n",
        "    transforms.RandomHorizontalFlip(p=1),\n",
        "    transforms.ColorJitter(brightness=0.5),\n",
        "    transforms.ColorJitter(contrast=0.5),\n",
        "    transforms.ColorJitter(saturation=1.0),\n",
        "    transforms.ColorJitter(hue=0.3),\n",
        "    transforms.RandomPerspective(distortion_scale=0.4, p=1),\n",
        "    transforms.GaussianBlur(kernel_size=(9, 9)),\n",
        "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
        "    transforms.RandomGrayscale(p=1),\n",
        "]\n",
        "\n",
        "def augment_and_save(img_path, save_dir, base_name):\n",
        "    image = Image.open(img_path).convert('RGB')\n",
        "    image.save(os.path.join(save_dir, f\"{base_name}_orig.jpg\"))\n",
        "    for i, transform in enumerate(augmentation_transforms):\n",
        "        augmented = transform(image)\n",
        "        augmented.save(os.path.join(save_dir, f\"{base_name}_aug{i+1}.jpg\"))\n",
        "\n",
        "# ---------------------- Step 1: Organize and Augment DB ----------------------\n",
        "for file in os.listdir(db_path):\n",
        "    if file.lower().endswith(supported_exts) and os.path.isfile(os.path.join(db_path, file)):\n",
        "        actor_name = os.path.splitext(file)[0]\n",
        "        actor_dir = os.path.join(db_path, actor_name)\n",
        "        os.makedirs(actor_dir, exist_ok=True)\n",
        "        img_path = os.path.join(db_path, file)\n",
        "        augment_and_save(img_path, actor_dir, actor_name)\n",
        "        os.remove(img_path)\n",
        "\n",
        "# ---------------------- Step 2: Load DB Embeddings ----------------------\n",
        "\n",
        "def get_face_embeddings(image):\n",
        "    faces = app.get(image)\n",
        "    embeddings, bboxes = [], []\n",
        "    for face in faces:\n",
        "        embeddings.append(face.embedding)\n",
        "        bboxes.append(face.bbox)\n",
        "    return embeddings, bboxes\n",
        "\n",
        "db_embeddings, db_names = [], []\n",
        "actor_dirs = [d for d in os.listdir(db_path) if os.path.isdir(os.path.join(db_path, d))]\n",
        "\n",
        "for actor in actor_dirs:\n",
        "    actor_folder = os.path.join(db_path, actor)\n",
        "    actor_embeddings = []\n",
        "    for file in os.listdir(actor_folder):\n",
        "        if file.lower().endswith(supported_exts):\n",
        "            img_path = os.path.join(actor_folder, file)\n",
        "            img = cv2.imread(img_path)\n",
        "            if img is not None:\n",
        "                emb, _ = get_face_embeddings(img)\n",
        "                if emb:\n",
        "                    actor_embeddings.append(emb[0])\n",
        "    if actor_embeddings:\n",
        "        avg_emb = np.mean(actor_embeddings, axis=0)\n",
        "        db_embeddings.append(avg_emb)\n",
        "        db_names.append(actor)\n",
        "\n",
        "# ---------------------- Step 3: Face Matching ----------------------\n",
        "def match_faces(group_embeddings, db_embeddings, threshold=0.35):\n",
        "    matched_labels, similarity_scores = [], []\n",
        "    for g_emb in group_embeddings:\n",
        "        sims = cosine_similarity([g_emb], db_embeddings)[0]\n",
        "        best_idx = np.argmax(sims)\n",
        "        best_score = sims[best_idx]\n",
        "        matched_labels.append(best_idx if best_score > threshold else None)\n",
        "        similarity_scores.append(best_score)\n",
        "    return matched_labels, similarity_scores\n",
        "\n",
        "def annotate_faces(image, bboxes, labels, names, scores):\n",
        "    predicted_names = []\n",
        "    y_offsets = {}\n",
        "    for i, (bbox, label, score) in enumerate(zip(bboxes, labels, scores)):\n",
        "        if label is None:\n",
        "            predicted_names.append(\"Unknown\")\n",
        "            continue\n",
        "        x1, y1, x2, y2 = map(int, bbox)\n",
        "        name = names[label]\n",
        "        predicted_names.append(name)\n",
        "        color = (0, 255, 0)\n",
        "        cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)\n",
        "\n",
        "        # Avoid overlapping names\n",
        "        key = (x1 // 10) * 10\n",
        "        offset = y_offsets.get(key, 0)\n",
        "        y_offsets[key] = offset + 20\n",
        "        text_y = max(10, y1 - 10 + offset)\n",
        "\n",
        "        cv2.putText(image, f\"{name} ({score:.2f})\", (x1, text_y),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.55, color, 2)\n",
        "    return image, predicted_names\n",
        "\n",
        "# ---------------------- Step 4: Process Group Photos ----------------------\n",
        "total_TP, total_FP, total_FN, total_TN = 0, 0, 0, 0\n",
        "precision_list, recall_list, f1_list, acc_list = [], [], [], []\n",
        "\n",
        "for file in os.listdir(group_photo_dir):\n",
        "    if file.lower().endswith(supported_exts):\n",
        "        print(f\"\\n{'=' * 30}\\nðŸ“¸ Processing: {file}\")\n",
        "        img_path = os.path.join(group_photo_dir, file)\n",
        "        group_img = cv2.imread(img_path)\n",
        "\n",
        "        group_embeddings, group_bboxes = get_face_embeddings(group_img)\n",
        "        matched_indices, scores = match_faces(group_embeddings, db_embeddings)\n",
        "\n",
        "        annotated_img, predicted_names = annotate_faces(group_img.copy(), group_bboxes, matched_indices, db_names, scores)\n",
        "\n",
        "        # Resize for consistent visualization\n",
        "        height, width = annotated_img.shape[:2]\n",
        "        new_height = int((standard_display_width / width) * height)\n",
        "        annotated_img_resized = cv2.resize(annotated_img, (standard_display_width, new_height))\n",
        "        cv2_imshow(annotated_img_resized)\n",
        "\n",
        "        # Evaluation\n",
        "        TP, FP, FN, TN = 0, 0, 0, 0\n",
        "        name_counts = {}\n",
        "\n",
        "        for name, score in zip(predicted_names, scores):\n",
        "            if name == \"Unknown\":\n",
        "                TN += 1\n",
        "            else:\n",
        "                name_counts[name] = name_counts.get(name, 0) + 1\n",
        "                if name in db_names:\n",
        "                    TP += 1\n",
        "\n",
        "        # Count false positives: duplicate names\n",
        "        FP = sum(count - 1 for count in name_counts.values() if count > 1)\n",
        "\n",
        "        # Count false negatives for missed faces within similarity range\n",
        "        for emb in group_embeddings:\n",
        "            sims = cosine_similarity([emb], db_embeddings)[0]\n",
        "            best_score = np.max(sims)\n",
        "            if 0.2 <= best_score < 0.35:\n",
        "                FN += 1\n",
        "\n",
        "        total_TP += TP\n",
        "        total_FP += FP\n",
        "        total_FN += FN\n",
        "        total_TN += TN\n",
        "\n",
        "        precision = TP / (TP + FP + 1e-6)\n",
        "        recall = TP / (TP + FN + 1e-6)\n",
        "        f1 = 2 * precision * recall / (precision + recall + 1e-6)\n",
        "        accuracy = (TP + TN) / (TP + TN + FP + FN + 1e-6)\n",
        "\n",
        "        precision_list.append(precision)\n",
        "        recall_list.append(recall)\n",
        "        f1_list.append(f1)\n",
        "        acc_list.append(accuracy)\n",
        "\n",
        "# ---------------------- Final Averaged Metrics ----------------------\n",
        "print(\"\\n\" + \"=\" * 40)\n",
        "print(\"ðŸ“Š Final Evaluation Summary Across All Group Photos\")\n",
        "print(f\"âœ… Total True Positives     : {total_TP}\")\n",
        "print(f\"âŒ Total False Positives    : {total_FP}\")\n",
        "print(f\"ðŸš« Total False Negatives    : {total_FN} (similarity 0.2â€“0.34)\")\n",
        "print(f\"ðŸŸ¦ Total True Negatives     : {total_TN}\")\n",
        "print(\"-\" * 40)\n",
        "print(f\"ðŸ“Š Average Accuracy         : {np.mean(acc_list):.2f}\")\n",
        "print(f\"ðŸ“Š Average Precision        : {np.mean(precision_list):.2f}\")\n",
        "print(f\"ðŸ“Š Average Recall           : {np.mean(recall_list):.2f}\")\n",
        "print(f\"ðŸ“Š Average F1 Score         : {np.mean(f1_list):.2f}\")\n",
        "print(\"=\" * 40)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7na8JTVeDOEb"
      },
      "source": [
        "# New Section"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}